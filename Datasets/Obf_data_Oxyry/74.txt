""#line:3:"""
import logging #line:4:import logging
import re #line:5:import re
import calendar #line:6:import calendar
import time #line:7:import time
from email .utils import parsedate_tz #line:8:from email.utils import parsedate_tz
from pip ._vendor .requests .structures import CaseInsensitiveDict #line:10:from pip._vendor.requests.structures import CaseInsensitiveDict
from .cache import DictCache #line:12:from .cache import DictCache
from .serialize import Serializer #line:13:from .serialize import Serializer
logger =logging .getLogger (__name__ )#line:16:logger = logging.getLogger(__name__)
URI =re .compile (r"^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\?([^#]*))?(#(.*))?")#line:18:URI = re.compile(r"^(([^:/?#]+):)?(//([^/?#]*))?([^?#]*)(\?([^#]*))?(#(.*))?")
def parse_uri (O0OOO0OO0O0OO0O0O ):#line:21:def parse_uri(uri):
    ""#line:25:"""
    O0O0OO00OOO0O00O0 =URI .match (O0OOO0OO0O0OO0O0O ).groups ()#line:26:groups = URI.match(uri).groups()
    return (O0O0OO00OOO0O00O0 [1 ],O0O0OO00OOO0O00O0 [3 ],O0O0OO00OOO0O00O0 [4 ],O0O0OO00OOO0O00O0 [6 ],O0O0OO00OOO0O00O0 [8 ])#line:27:return (groups[1], groups[3], groups[4], groups[6], groups[8])
class CacheController (object ):#line:30:class CacheController(object):
    ""#line:32:"""
    def __init__ (O0OOO00O0OOOO0OO0 ,cache =None ,cache_etags =True ,serializer =None ,status_codes =None ):#line:36:):
        O0OOO00O0OOOO0OO0 .cache =cache or DictCache ()#line:37:self.cache = cache or DictCache()
        O0OOO00O0OOOO0OO0 .cache_etags =cache_etags #line:38:self.cache_etags = cache_etags
        O0OOO00O0OOOO0OO0 .serializer =serializer or Serializer ()#line:39:self.serializer = serializer or Serializer()
        O0OOO00O0OOOO0OO0 .cacheable_status_codes =status_codes or (200 ,203 ,300 ,301 )#line:40:self.cacheable_status_codes = status_codes or (200, 203, 300, 301)
    @classmethod #line:42:@classmethod
    def _urlnorm (O0OO0OO0O0OO000O0 ,O00O000OOOOO0O0OO ):#line:43:def _urlnorm(cls, uri):
        ""#line:44:"""Normalize the URL to create a safe key for the cache"""
        (OO000O0O0O0O0O0O0 ,OO00000OOOO0OO000 ,O0O0OOOOO0OOO000O ,OOO000OO0000OO0OO ,O00OO00OO0O0OOO00 )=parse_uri (O00O000OOOOO0O0OO )#line:45:(scheme, authority, path, query, fragment) = parse_uri(uri)
        if not OO000O0O0O0O0O0O0 or not OO00000OOOO0OO000 :#line:46:if not scheme or not authority:
            raise Exception ("Only absolute URIs are allowed. uri = %s"%O00O000OOOOO0O0OO )#line:47:raise Exception("Only absolute URIs are allowed. uri = %s" % uri)
        OO000O0O0O0O0O0O0 =OO000O0O0O0O0O0O0 .lower ()#line:49:scheme = scheme.lower()
        OO00000OOOO0OO000 =OO00000OOOO0OO000 .lower ()#line:50:authority = authority.lower()
        if not O0O0OOOOO0OOO000O :#line:52:if not path:
            O0O0OOOOO0OOO000O ="/"#line:53:path = "/"
        O0O0OOOO0OO0O00OO =OOO000OO0000OO0OO and "?".join ([O0O0OOOOO0OOO000O ,OOO000OO0000OO0OO ])or O0O0OOOOO0OOO000O #line:57:request_uri = query and "?".join([path, query]) or path
        O0O0OO0O00OOOO0O0 =OO000O0O0O0O0O0O0 +"://"+OO00000OOOO0OO000 +O0O0OOOO0OO0O00OO #line:58:defrag_uri = scheme + "://" + authority + request_uri
        return O0O0OO0O00OOOO0O0 #line:60:return defrag_uri
    @classmethod #line:62:@classmethod
    def cache_url (O0O0O0OOO000O000O ,OOO0OOO0O0OOOOOOO ):#line:63:def cache_url(cls, uri):
        return O0O0O0OOO000O000O ._urlnorm (OOO0OOO0O0OOOOOOO )#line:64:return cls._urlnorm(uri)
    def parse_cache_control (O0O000OO0OOO000O0 ,O00O0O00O0O0O00OO ):#line:66:def parse_cache_control(self, headers):
        O0O0O0O0O0OO0O00O ={"max-age":(int ,True ),"max-stale":(int ,False ),"min-fresh":(int ,True ),"no-cache":(None ,False ),"no-store":(None ,False ),"no-transform":(None ,False ),"only-if-cached":(None ,False ),"must-revalidate":(None ,False ),"public":(None ,False ),"private":(None ,False ),"proxy-revalidate":(None ,False ),"s-maxage":(int ,True ),}#line:81:}
        O000000OOOOO0O00O =O00O0O00O0O0O00OO .get ("cache-control",O00O0O00O0O0O00OO .get ("Cache-Control",""))#line:83:cc_headers = headers.get("cache-control", headers.get("Cache-Control", ""))
        OOO00O0OO0O00OOO0 ={}#line:85:retval = {}
        for OO0O0O00O0OOOOO0O in O000000OOOOO0O00O .split (","):#line:87:for cc_directive in cc_headers.split(","):
            if not OO0O0O00O0OOOOO0O .strip ():#line:88:if not cc_directive.strip():
                continue #line:89:continue
            OOOOO0000O0O00000 =OO0O0O00O0OOOOO0O .split ("=",1 )#line:91:parts = cc_directive.split("=", 1)
            O00O0OOOOOOOO0OO0 =OOOOO0000O0O00000 [0 ].strip ()#line:92:directive = parts[0].strip()
            try :#line:94:try:
                OO0O00O000O00OOOO ,O0O0OOO0O0O0O0OOO =O0O0O0O0O0OO0O00O [O00O0OOOOOOOO0OO0 ]#line:95:typ, required = known_directives[directive]
            except KeyError :#line:96:except KeyError:
                logger .debug ("Ignoring unknown cache-control directive: %s",O00O0OOOOOOOO0OO0 )#line:97:logger.debug("Ignoring unknown cache-control directive: %s", directive)
                continue #line:98:continue
            if not OO0O00O000O00OOOO or not O0O0OOO0O0O0O0OOO :#line:100:if not typ or not required:
                OOO00O0OO0O00OOO0 [O00O0OOOOOOOO0OO0 ]=None #line:101:retval[directive] = None
            if OO0O00O000O00OOOO :#line:102:if typ:
                try :#line:103:try:
                    OOO00O0OO0O00OOO0 [O00O0OOOOOOOO0OO0 ]=OO0O00O000O00OOOO (OOOOO0000O0O00000 [1 ].strip ())#line:104:retval[directive] = typ(parts[1].strip())
                except IndexError :#line:105:except IndexError:
                    if O0O0OOO0O0O0O0OOO :#line:106:if required:
                        logger .debug ("Missing value for cache-control " "directive: %s",O00O0OOOOOOOO0OO0 ,)#line:110:)
                except ValueError :#line:111:except ValueError:
                    logger .debug ("Invalid value for cache-control directive " "%s, must be %s",O00O0OOOOOOOO0OO0 ,OO0O00O000O00OOOO .__name__ ,)#line:116:)
        return OOO00O0OO0O00OOO0 #line:118:return retval
    def cached_request (O0O0O000000O0O000 ,O00OOO0O0O0000O0O ):#line:120:def cached_request(self, request):
        ""#line:124:"""
        O0O00000O0000OO00 =O0O0O000000O0O000 .cache_url (O00OOO0O0O0000O0O .url )#line:125:cache_url = self.cache_url(request.url)
        logger .debug ('Looking up "%s" in the cache',O0O00000O0000OO00 )#line:126:logger.debug('Looking up "%s" in the cache', cache_url)
        OO00O00O0O0OOOO0O =O0O0O000000O0O000 .parse_cache_control (O00OOO0O0O0000O0O .headers )#line:127:cc = self.parse_cache_control(request.headers)
        if "no-cache"in OO00O00O0O0OOOO0O :#line:130:if "no-cache" in cc:
            logger .debug ('Request header has "no-cache", cache bypassed')#line:131:logger.debug('Request header has "no-cache", cache bypassed')
            return False #line:132:return False
        if "max-age"in OO00O00O0O0OOOO0O and OO00O00O0O0OOOO0O ["max-age"]==0 :#line:134:if "max-age" in cc and cc["max-age"] == 0:
            logger .debug ('Request header has "max_age" as 0, cache bypassed')#line:135:logger.debug('Request header has "max_age" as 0, cache bypassed')
            return False #line:136:return False
        OOOOO000O000O0OO0 =O0O0O000000O0O000 .cache .get (O0O00000O0000OO00 )#line:139:cache_data = self.cache.get(cache_url)
        if OOOOO000O000O0OO0 is None :#line:140:if cache_data is None:
            logger .debug ("No cache entry available")#line:141:logger.debug("No cache entry available")
            return False #line:142:return False
        O0OOOOO0OOO0O0OOO =O0O0O000000O0O000 .serializer .loads (O00OOO0O0O0000O0O ,OOOOO000O000O0OO0 )#line:145:resp = self.serializer.loads(request, cache_data)
        if not O0OOOOO0OOO0O0OOO :#line:146:if not resp:
            logger .warning ("Cache entry deserialization failed, entry ignored")#line:147:logger.warning("Cache entry deserialization failed, entry ignored")
            return False #line:148:return False
        if O0OOOOO0OOO0O0OOO .status ==301 :#line:158:if resp.status == 301:
            OO0O000OOOOOOOOO0 =('Returning cached "301 Moved Permanently" response ' "(ignoring date and etag information)")#line:162:)
            logger .debug (OO0O000OOOOOOOOO0 )#line:163:logger.debug(msg)
            return O0OOOOO0OOO0O0OOO #line:164:return resp
        O00000000OO000O00 =CaseInsensitiveDict (O0OOOOO0OOO0O0OOO .headers )#line:166:headers = CaseInsensitiveDict(resp.headers)
        if not O00000000OO000O00 or "date"not in O00000000OO000O00 :#line:167:if not headers or "date" not in headers:
            if "etag"not in O00000000OO000O00 :#line:168:if "etag" not in headers:
                logger .debug ("Purging cached response: no date or etag")#line:171:logger.debug("Purging cached response: no date or etag")
                O0O0O000000O0O000 .cache .delete (O0O00000O0000OO00 )#line:172:self.cache.delete(cache_url)
            logger .debug ("Ignoring cached response: no date")#line:173:logger.debug("Ignoring cached response: no date")
            return False #line:174:return False
        O0OOOOOOOO00000OO =time .time ()#line:176:now = time.time()
        O00OO00OO00O0OO00 =calendar .timegm (parsedate_tz (O00000000OO000O00 ["date"]))#line:177:date = calendar.timegm(parsedate_tz(headers["date"]))
        O0O00O0OOOO000OO0 =max (0 ,O0OOOOOOOO00000OO -O00OO00OO00O0OO00 )#line:178:current_age = max(0, now - date)
        logger .debug ("Current age based on date: %i",O0O00O0OOOO000OO0 )#line:179:logger.debug("Current age based on date: %i", current_age)
        OOOO00000000O0O00 =O0O0O000000O0O000 .parse_cache_control (O00000000OO000O00 )#line:185:resp_cc = self.parse_cache_control(headers)
        OO00OO0OOOO0000O0 =0 #line:188:freshness_lifetime = 0
        if "max-age"in OOOO00000000O0O00 :#line:191:if "max-age" in resp_cc:
            OO00OO0OOOO0000O0 =OOOO00000000O0O00 ["max-age"]#line:192:freshness_lifetime = resp_cc["max-age"]
            logger .debug ("Freshness lifetime from max-age: %i",OO00OO0OOOO0000O0 )#line:193:logger.debug("Freshness lifetime from max-age: %i", freshness_lifetime)
        elif "expires"in O00000000OO000O00 :#line:196:elif "expires" in headers:
            O00OOO0000OO0O0O0 =parsedate_tz (O00000000OO000O00 ["expires"])#line:197:expires = parsedate_tz(headers["expires"])
            if O00OOO0000OO0O0O0 is not None :#line:198:if expires is not None:
                O0OOOO00O0OOO00OO =calendar .timegm (O00OOO0000OO0O0O0 )-O00OO00OO00O0OO00 #line:199:expire_time = calendar.timegm(expires) - date
                OO00OO0OOOO0000O0 =max (0 ,O0OOOO00O0OOO00OO )#line:200:freshness_lifetime = max(0, expire_time)
                logger .debug ("Freshness lifetime from expires: %i",OO00OO0OOOO0000O0 )#line:201:logger.debug("Freshness lifetime from expires: %i", freshness_lifetime)
        if "max-age"in OO00O00O0O0OOOO0O :#line:205:if "max-age" in cc:
            OO00OO0OOOO0000O0 =OO00O00O0O0OOOO0O ["max-age"]#line:206:freshness_lifetime = cc["max-age"]
            logger .debug ("Freshness lifetime from request max-age: %i",OO00OO0OOOO0000O0 )#line:209:)
        if "min-fresh"in OO00O00O0O0OOOO0O :#line:211:if "min-fresh" in cc:
            OO0O00O0OO00000O0 =OO00O00O0O0OOOO0O ["min-fresh"]#line:212:min_fresh = cc["min-fresh"]
            O0O00O0OOOO000OO0 +=OO0O00O0OO00000O0 #line:214:current_age += min_fresh
            logger .debug ("Adjusted current age from min-fresh: %i",O0O00O0OOOO000OO0 )#line:215:logger.debug("Adjusted current age from min-fresh: %i", current_age)
        if OO00OO0OOOO0000O0 >O0O00O0OOOO000OO0 :#line:218:if freshness_lifetime > current_age:
            logger .debug ('The response is "fresh", returning cached response')#line:219:logger.debug('The response is "fresh", returning cached response')
            logger .debug ("%i > %i",OO00OO0OOOO0000O0 ,O0O00O0OOOO000OO0 )#line:220:logger.debug("%i > %i", freshness_lifetime, current_age)
            return O0OOOOO0OOO0O0OOO #line:221:return resp
        if "etag"not in O00000000OO000O00 :#line:224:if "etag" not in headers:
            logger .debug ('The cached response is "stale" with no etag, purging')#line:225:logger.debug('The cached response is "stale" with no etag, purging')
            O0O0O000000O0O000 .cache .delete (O0O00000O0000OO00 )#line:226:self.cache.delete(cache_url)
        return False #line:229:return False
    def conditional_headers (O00OOOOOOOO00O000 ,OO0OOOO000OOOOOOO ):#line:231:def conditional_headers(self, request):
        O00000OO0O0OO0000 =O00OOOOOOOO00O000 .cache_url (OO0OOOO000OOOOOOO .url )#line:232:cache_url = self.cache_url(request.url)
        O000O00OO00O00OOO =O00OOOOOOOO00O000 .serializer .loads (OO0OOOO000OOOOOOO ,O00OOOOOOOO00O000 .cache .get (O00000OO0O0OO0000 ))#line:233:resp = self.serializer.loads(request, self.cache.get(cache_url))
        O0O0O0O0000O0000O ={}#line:234:new_headers = {}
        if O000O00OO00O00OOO :#line:236:if resp:
            O00OOOOO0000000OO =CaseInsensitiveDict (O000O00OO00O00OOO .headers )#line:237:headers = CaseInsensitiveDict(resp.headers)
            if "etag"in O00OOOOO0000000OO :#line:239:if "etag" in headers:
                O0O0O0O0000O0000O ["If-None-Match"]=O00OOOOO0000000OO ["ETag"]#line:240:new_headers["If-None-Match"] = headers["ETag"]
            if "last-modified"in O00OOOOO0000000OO :#line:242:if "last-modified" in headers:
                O0O0O0O0000O0000O ["If-Modified-Since"]=O00OOOOO0000000OO ["Last-Modified"]#line:243:new_headers["If-Modified-Since"] = headers["Last-Modified"]
        return O0O0O0O0000O0000O #line:245:return new_headers
    def cache_response (O00OO000O0000O0OO ,O0OO00OOOOO000OOO ,O0OOOO0OO0000O0OO ,body =None ,status_codes =None ):#line:247:def cache_response(self, request, response, body=None, status_codes=None):
        ""#line:252:"""
        OO00O0O0000OO00OO =status_codes or O00OO000O0000O0OO .cacheable_status_codes #line:255:cacheable_status_codes = status_codes or self.cacheable_status_codes
        if O0OOOO0OO0000O0OO .status not in OO00O0O0000OO00OO :#line:256:if response.status not in cacheable_status_codes:
            logger .debug ("Status code %s not in %s",O0OOOO0OO0000O0OO .status ,OO00O0O0000OO00OO )#line:259:)
            return #line:260:return
        O0O0O0OOO0000OO0O =CaseInsensitiveDict (O0OOOO0OO0000O0OO .headers )#line:262:response_headers = CaseInsensitiveDict(response.headers)
        if (body is not None and "content-length"in O0O0O0OOO0000OO0O and O0O0O0OOO0000OO0O ["content-length"].isdigit ()and int (O0O0O0OOO0000OO0O ["content-length"])!=len (body )):#line:273:):
            return #line:274:return
        OO0OOOOO0OOO00OOO =O00OO000O0000O0OO .parse_cache_control (O0OO00OOOOO000OOO .headers )#line:276:cc_req = self.parse_cache_control(request.headers)
        OO0OOOOOOO000O00O =O00OO000O0000O0OO .parse_cache_control (O0O0O0OOO0000OO0O )#line:277:cc = self.parse_cache_control(response_headers)
        OOO000000OO0OOO0O =O00OO000O0000O0OO .cache_url (O0OO00OOOOO000OOO .url )#line:279:cache_url = self.cache_url(request.url)
        logger .debug ('Updating cache with response from "%s"',OOO000000OO0OOO0O )#line:280:logger.debug('Updating cache with response from "%s"', cache_url)
        OOO0000OOOOOO0OO0 =False #line:283:no_store = False
        if "no-store"in OO0OOOOOOO000O00O :#line:284:if "no-store" in cc:
            OOO0000OOOOOO0OO0 =True #line:285:no_store = True
            logger .debug ('Response header has "no-store"')#line:286:logger.debug('Response header has "no-store"')
        if "no-store"in OO0OOOOO0OOO00OOO :#line:287:if "no-store" in cc_req:
            OOO0000OOOOOO0OO0 =True #line:288:no_store = True
            logger .debug ('Request header has "no-store"')#line:289:logger.debug('Request header has "no-store"')
        if OOO0000OOOOOO0OO0 and O00OO000O0000O0OO .cache .get (OOO000000OO0OOO0O ):#line:290:if no_store and self.cache.get(cache_url):
            logger .debug ('Purging existing cache entry to honor "no-store"')#line:291:logger.debug('Purging existing cache entry to honor "no-store"')
            O00OO000O0000O0OO .cache .delete (OOO000000OO0OOO0O )#line:292:self.cache.delete(cache_url)
        if OOO0000OOOOOO0OO0 :#line:293:if no_store:
            return #line:294:return
        if O00OO000O0000O0OO .cache_etags and "etag"in O0O0O0OOO0000OO0O :#line:297:if self.cache_etags and "etag" in response_headers:
            logger .debug ("Caching due to etag")#line:298:logger.debug("Caching due to etag")
            O00OO000O0000O0OO .cache .set (OOO000000OO0OOO0O ,O00OO000O0000O0OO .serializer .dumps (O0OO00OOOOO000OOO ,O0OOOO0OO0000O0OO ,body =body ))#line:301:)
        elif O0OOOO0OO0000O0OO .status ==301 :#line:305:elif response.status == 301:
            logger .debug ("Caching permanant redirect")#line:306:logger.debug("Caching permanant redirect")
            O00OO000O0000O0OO .cache .set (OOO000000OO0OOO0O ,O00OO000O0000O0OO .serializer .dumps (O0OO00OOOOO000OOO ,O0OOOO0OO0000O0OO ))#line:307:self.cache.set(cache_url, self.serializer.dumps(request, response))
        elif "date"in O0O0O0OOO0000OO0O :#line:312:elif "date" in response_headers:
            if "max-age"in OO0OOOOOOO000O00O and OO0OOOOOOO000O00O ["max-age"]>0 :#line:314:if "max-age" in cc and cc["max-age"] > 0:
                logger .debug ("Caching b/c date exists and max-age > 0")#line:315:logger.debug("Caching b/c date exists and max-age > 0")
                O00OO000O0000O0OO .cache .set (OOO000000OO0OOO0O ,O00OO000O0000O0OO .serializer .dumps (O0OO00OOOOO000OOO ,O0OOOO0OO0000O0OO ,body =body ))#line:318:)
            elif "expires"in O0O0O0OOO0000OO0O :#line:322:elif "expires" in response_headers:
                if O0O0O0OOO0000OO0O ["expires"]:#line:323:if response_headers["expires"]:
                    logger .debug ("Caching b/c of expires header")#line:324:logger.debug("Caching b/c of expires header")
                    O00OO000O0000O0OO .cache .set (OOO000000OO0OOO0O ,O00OO000O0000O0OO .serializer .dumps (O0OO00OOOOO000OOO ,O0OOOO0OO0000O0OO ,body =body ))#line:327:)
    def update_cached_response (OOOOO00O0O00000O0 ,O00O0O00O0OOO00OO ,OOO00O000O000O0OO ):#line:329:def update_cached_response(self, request, response):
        ""#line:335:"""
        OO0OO0O00OO0O0O00 =OOOOO00O0O00000O0 .cache_url (O00O0O00O0OOO00OO .url )#line:336:cache_url = self.cache_url(request.url)
        O00OOO0OO00OO0O0O =OOOOO00O0O00000O0 .serializer .loads (O00O0O00O0OOO00OO ,OOOOO00O0O00000O0 .cache .get (OO0OO0O00OO0O0O00 ))#line:338:cached_response = self.serializer.loads(request, self.cache.get(cache_url))
        if not O00OOO0OO00OO0O0O :#line:340:if not cached_response:
            return OOO00O000O000O0OO #line:342:return response
        OO00O0OO0O0O00O0O =["content-length"]#line:351:excluded_headers = ["content-length"]
        O00OOO0OO00OO0O0O .headers .update (dict ((O0OOO00OOO0OO0O0O ,OO0000O0OOO00OO0O )for O0OOO00OOO0OO0O0O ,OO0000O0OOO00OO0O in OOO00O000O000O0OO .headers .items ()if O0OOO00OOO0OO0O0O .lower ()not in OO00O0OO0O0O00O0O ))#line:359:)
        O00OOO0OO00OO0O0O .status =200 #line:362:cached_response.status = 200
        OOOOO00O0O00000O0 .cache .set (OO0OO0O00OO0O0O00 ,OOOOO00O0O00000O0 .serializer .dumps (O00O0O00O0OOO00OO ,O00OOO0OO00OO0O0O ))#line:365:self.cache.set(cache_url, self.serializer.dumps(request, cached_response))
        return O00OOO0OO00OO0O0O #line:367:return cached_response
